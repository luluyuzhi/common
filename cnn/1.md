> **backbone：**
>
> 作者并没有使用VGG作为backbone了，而是使用MobileNet。但是作者发现单纯的直接使用MobileNet效果并不好，效果不好的原因是MobileNet网络结构不够深，所以感受野不够大。为什么感受野不大就会影响性能，个人分析主要有两个方面原因：一是我们在回归一个骨骼点时，不仅仅要关注骨骼点附近的情况，还应该关注更大的范围，这样才能较少误报；二是因为本身骨骼点的回归，肯定是能够学到一定的骨骼连接结构信息的，这也是为什么有时候明明骨骼点被遮挡了，但是网络仍旧能够定位到这个点的原因。
>
> > 为了解决因为感受野太小而造成的效果不好，作者通过使用空洞卷积（dilated convolution）来提升感受野。
>
> **refinement stage：**
>
> 在OpenPose中，为了生成keypoint heatmaps和paf，其构造了两个branch，一个branch用来生成keypoint heatmap，一个用来生成paf。并将这个生成heatmap的步骤称为refinement stage。

时序动作提名生成任务的目的是给未裁剪的长视频生成一定数量的时序动作提名，一个时序提名即是一个可能包含动作片段的时序区间（从开始边界到结束边界），

1. 提出算法名称， 命名英文 命名 中文

2. 图的横纵坐标 必须有单位，最好是中文
3. 目录
4. 整个智慧不要提了，过激行为 ， 没有违规 
5. 原来的算法和自己的思想融合起来
6. 主动和被动





数据集





stn ：空间变换网络 

目的：

我们希望STN对feature map进行变换后能把图像纠正到成理想的图像，然后丢进NN去识别，举例来说，**如下图所示**，输入模型的图像可能是摆着各种姿势，摆在不同位置的凉宫春日，我们希望STN把它纠正到图像的正中央，放大，占满整个屏幕，然后再丢进CNN去识别。

https://www.cnblogs.com/liaohuiqiang/p/9226335.html

经过 stn 变换后的图像的标签不需要重新设置。



由于不同场景下的视频拍摄习惯，导致视频的拍摄角度也不同，因此需要调正相片的角度。



通过stn变换保证形变-》hog+svm+nms 回归出人体候选框-》hrnet + 空洞卷积回归 骨骼关节点。



时序动作提名

数据集：。该方法最终在 ActivityNet-1.3 和 THUMOS14 

注意力机制能不能学习



**空洞卷积的作用**
扩大感受野：在deep net中为了增加感受野且降低计算量，总要进行降采样(pooling或s2/conv)，这样虽然可以增加感受野，但空间分辨率降低了，进而导致信息丢失。为了能不丢失分辨率，且仍然扩大感受野，可以使用空洞卷积。这在检测，分割任务中十分有用。一方面感受野大了可以检测分割大目标，另一方面分辨率高了可以精确定位目标。

捕获多尺度上下文信息：空洞卷积有一个参数可以设置dilation rate，具体含义就是在卷积核中填充dilation rate-1个0，因此，当设置不同dilation rate时，感受野就会不一样，也即获取了多尺度信息。多尺度信息在视觉任务中相当重要。



我将HRNet整个backbone部分进行了拆解，分成4个stage，每个stage分成蓝色框和橙色框两部分。其中蓝色框部分是每个stage的基本结构，由多个branch组成，HRNet中stage1蓝色框使用的是BottleNeck，stage2&3&4蓝色框使用的是BasicBlock。其中橙色框部分是每个stage的过渡结构，HRNet中stage1橙色框是一个TransitionLayer，stage2&3橙色框是一个FuseLayer和一个TransitionLayer的叠加，stage4橙色框是一个FuseLayer。

仿射变换：https://zhuanlan.zhihu.com/p/80852438



图节点：

每个节点的定义是由该节点的特征和相关节点来共同表示的
